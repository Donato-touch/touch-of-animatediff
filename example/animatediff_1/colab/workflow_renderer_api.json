{
  "1": {
    "inputs": {
      "video": "E:\\test\\touch-of-animatediff\\example\\resource\\test_dance.mp4",
      "force_rate": 15,
      "force_size": "512x?",
      "custom_width": 512,
      "custom_height": 512,
      "frame_load_cap": [
        "6",
        0
      ],
      "skip_first_frames": [
        "8",
        0
      ],
      "select_every_nth": 1
    },
    "class_type": "VHS_LoadVideoPath",
    "_meta": {
      "title": "Load original video"
    }
  },
  "2": {
    "inputs": {
      "ckpt_name": "meinamix_meinaV11.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "3": {
    "inputs": {
      "vae_name": "vae-ft-mse-840000-ema-pruned.ckpt"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "4": {
    "inputs": {
      "stop_at_clip_layer": -2,
      "clip": [
        "2",
        1
      ]
    },
    "class_type": "CLIPSetLastLayer",
    "_meta": {
      "title": "CLIP Set Last Layer"
    }
  },
  "5": {
    "inputs": {
      "switch": "On",
      "lora_name": "LCM_LoRA_Weights_SD15.safetensors",
      "strength_model": 1,
      "strength_clip": 1,
      "model": [
        "2",
        0
      ],
      "clip": [
        "4",
        0
      ]
    },
    "class_type": "CR Load LoRA",
    "_meta": {
      "title": "üíä CR Load LoRA"
    }
  },
  "6": {
    "inputs": {
      "value": 20
    },
    "class_type": "INTConstant",
    "_meta": {
      "title": "Batch size"
    }
  },
  "8": {
    "inputs": {
      "value": "a*b",
      "a": [
        "34",
        0
      ],
      "b": [
        "6",
        0
      ]
    },
    "class_type": "SimpleMath+",
    "_meta": {
      "title": "üîß Simple Math"
    }
  },
  "9": {
    "inputs": {
      "text": "(smile), masterpiece, best quality, ultra detailed, (white off background)",
      "clip": [
        "5",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "Positive prompt"
    }
  },
  "10": {
    "inputs": {
      "detect_hand": "enable",
      "detect_body": "enable",
      "detect_face": "enable",
      "resolution": 512,
      "bbox_detector": "yolox_l.torchscript.pt",
      "pose_estimator": "dw-ll_ucoco_384_bs5.torchscript.pt",
      "scale_stick_for_xinsr_cn": "disable",
      "image": [
        "1",
        0
      ]
    },
    "class_type": "DWPreprocessor",
    "_meta": {
      "title": "DWPose Estimator"
    }
  },
  "11": {
    "inputs": {
      "text": "(worst quality, low quality:1.2), bad_pictures, bad hand, (logo, text, watermark:1.2)",
      "clip": [
        "5",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "Negative prompt"
    }
  },
  "12": {
    "inputs": {
      "beta_schedule": "lcm",
      "model": [
        "5",
        0
      ],
      "m_models": [
        "13",
        0
      ],
      "context_options": [
        "15",
        0
      ]
    },
    "class_type": "ADE_UseEvolvedSampling",
    "_meta": {
      "title": "Use Evolved Sampling üé≠üÖêüÖì‚ë°"
    }
  },
  "13": {
    "inputs": {
      "start_percent": 0,
      "end_percent": 1,
      "motion_model": [
        "14",
        0
      ]
    },
    "class_type": "ADE_ApplyAnimateDiffModel",
    "_meta": {
      "title": "Apply AnimateDiff Model (Adv.) üé≠üÖêüÖì‚ë°"
    }
  },
  "14": {
    "inputs": {
      "model_name": "motionModel_v03anime.ckpt"
    },
    "class_type": "ADE_LoadAnimateDiffModel",
    "_meta": {
      "title": "Load AnimateDiff Model üé≠üÖêüÖì‚ë°"
    }
  },
  "15": {
    "inputs": {
      "context_length": 16,
      "context_stride": 1,
      "context_overlap": 4,
      "fuse_method": "pyramid",
      "use_on_equal_length": false,
      "start_percent": 0,
      "guarantee_steps": 1
    },
    "class_type": "ADE_StandardUniformContextOptions",
    "_meta": {
      "title": "Context Options‚óÜStandard Uniform üé≠üÖêüÖì"
    }
  },
  "16": {
    "inputs": {
      "strength": 0.65,
      "start_percent": 0,
      "end_percent": 0.8,
      "positive": [
        "9",
        0
      ],
      "negative": [
        "11",
        0
      ],
      "control_net": [
        "18",
        0
      ],
      "image": [
        "17",
        0
      ],
      "model_optional": [
        "12",
        0
      ]
    },
    "class_type": "ACN_AdvancedControlNetApply",
    "_meta": {
      "title": "Apply Advanced ControlNet üõÇüÖêüÖíüÖù"
    }
  },
  "17": {
    "inputs": {
      "pyrUp_iters": 2,
      "resolution": 512,
      "image": [
        "1",
        0
      ]
    },
    "class_type": "TilePreprocessor",
    "_meta": {
      "title": "Tile"
    }
  },
  "18": {
    "inputs": {
      "control_net_name": "control_v11f1e_sd15_tile.pth"
    },
    "class_type": "ControlNetLoaderAdvanced",
    "_meta": {
      "title": "Load Advanced ControlNet Model üõÇüÖêüÖíüÖù"
    }
  },
  "19": {
    "inputs": {
      "strength": 0.65,
      "start_percent": 0,
      "end_percent": 0.8,
      "positive": [
        "16",
        0
      ],
      "negative": [
        "16",
        1
      ],
      "control_net": [
        "20",
        0
      ],
      "image": [
        "10",
        0
      ],
      "model_optional": [
        "16",
        2
      ]
    },
    "class_type": "ACN_AdvancedControlNetApply",
    "_meta": {
      "title": "Apply Advanced ControlNet üõÇüÖêüÖíüÖù"
    }
  },
  "20": {
    "inputs": {
      "control_net_name": "control_v11p_sd15_openpose.pth"
    },
    "class_type": "ControlNetLoaderAdvanced",
    "_meta": {
      "title": "Load Advanced ControlNet Model üõÇüÖêüÖíüÖù"
    }
  },
  "21": {
    "inputs": {
      "seed": [
        "22",
        0
      ],
      "steps": 7,
      "cfg": 1.7,
      "sampler_name": "lcm",
      "scheduler": "sgm_uniform",
      "denoise": 1,
      "model": [
        "19",
        2
      ],
      "positive": [
        "19",
        0
      ],
      "negative": [
        "19",
        1
      ],
      "latent_image": [
        "35",
        5
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "22": {
    "inputs": {
      "value": 135234
    },
    "class_type": "INTConstant",
    "_meta": {
      "title": "SEED"
    }
  },
  "23": {
    "inputs": {
      "model_name": "4xUltrasharp_4xUltrasharpV10.pth",
      "rescale_after_model": true,
      "rescale_method": "nearest-exact",
      "rescale": "by percentage",
      "percent": 38,
      "width": 1024,
      "height": 1024,
      "longer_side": 1024,
      "crop": "disabled",
      "image_output": "Hide",
      "save_prefix": "ComfyUI",
      "output_latent": true,
      "vae": [
        "3",
        0
      ],
      "image": [
        "24",
        0
      ]
    },
    "class_type": "ttN hiresfixScale",
    "_meta": {
      "title": "hiresfixScale"
    }
  },
  "24": {
    "inputs": {
      "samples": [
        "21",
        0
      ],
      "vae": [
        "3",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "26": {
    "inputs": {
      "seed": [
        "22",
        0
      ],
      "steps": 4,
      "cfg": 1.7,
      "sampler_name": "lcm",
      "scheduler": "sgm_uniform",
      "denoise": 0.25,
      "model": [
        "19",
        2
      ],
      "positive": [
        "19",
        0
      ],
      "negative": [
        "19",
        1
      ],
      "latent_image": [
        "23",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "28": {
    "inputs": {
      "samples": [
        "26",
        0
      ],
      "vae": [
        "3",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "29": {
    "inputs": {
      "bbox_threshold": 0.5,
      "bbox_dilation": 0,
      "crop_factor": 3,
      "drop_size": 10,
      "sub_threshold": 0.5,
      "sub_dilation": 0,
      "sub_bbox_expansion": 0,
      "sam_mask_hint_threshold": 0.7,
      "masking_mode": "Pivot SEGS",
      "segs_pivot": "Combined mask",
      "bbox_detector": [
        "30",
        0
      ],
      "image_frames": [
        "28",
        0
      ]
    },
    "class_type": "ImpactSimpleDetectorSEGS_for_AD",
    "_meta": {
      "title": "Simple Detector for AnimateDiff (SEGS)"
    }
  },
  "30": {
    "inputs": {
      "model_name": "bbox/face_yolov8m.pt"
    },
    "class_type": "UltralyticsDetectorProvider",
    "_meta": {
      "title": "UltralyticsDetectorProvider"
    }
  },
  "31": {
    "inputs": {
      "guide_size": 512,
      "guide_size_for": true,
      "max_size": 1024,
      "seed": [
        "22",
        0
      ],
      "steps": 4,
      "cfg": 1.7000000000000002,
      "sampler_name": "lcm",
      "scheduler": "sgm_uniform",
      "denoise": 0.25,
      "feather": 5,
      "refiner_ratio": 0.2,
      "noise_mask_feather": 20,
      "image_frames": [
        "28",
        0
      ],
      "segs": [
        "29",
        0
      ],
      "basic_pipe": [
        "32",
        0
      ]
    },
    "class_type": "DetailerForEachPipeForAnimateDiff",
    "_meta": {
      "title": "Detailer For AnimateDiff (SEGS/pipe)"
    }
  },
  "32": {
    "inputs": {
      "model": [
        "19",
        2
      ],
      "clip": [
        "5",
        1
      ],
      "vae": [
        "3",
        0
      ],
      "positive": [
        "19",
        0
      ],
      "negative": [
        "19",
        1
      ]
    },
    "class_type": "ToBasicPipe",
    "_meta": {
      "title": "ToBasicPipe"
    }
  },
  "33": {
    "inputs": {
      "filename_prefix": "img",
      "subfolder_dir": "detailed_out",
      "images": [
        "31",
        0
      ]
    },
    "class_type": "SaveImageCustomNode",
    "_meta": {
      "title": "Save Image Custom Node"
    }
  },
  "34": {
    "inputs": {
      "seed": 0
    },
    "class_type": "CR Seed",
    "_meta": {
      "title": "Loop index"
    }
  },
  "35": {
    "inputs": {
      "width": 1024,
      "height": 1024,
      "aspect_ratio": "SD1.5 - 2:3 portrait 512x768",
      "swap_dimensions": "Off",
      "upscale_factor": 1,
      "prescale_factor": 1,
      "batch_size": [
        "1",
        1
      ]
    },
    "class_type": "CR Aspect Ratio",
    "_meta": {
      "title": "üî≥ CR Aspect Ratio"
    }
  }
}